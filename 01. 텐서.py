# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.11.3
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

# í…ì„œ: ì¼ê´€ëœ ìœ í˜•ì„ ê°€ì§„ ë‹¤ì°¨ì› ë°°ì—´ (np.arrayì™€ ê°™ìŒ)
import tensorflow as tf
import numpy as np



# ------í…ì„œ ìƒì„±------

# scalar(Rank 0)
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
# -

# vector(Rank 1)
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)

# matrix(Rank 2)
rank_2_tensor = tf.constant([[1, 2],
                            [3, 4],
                            [5, 6]], dtype=tf.float16)
print(rank_2_tensor)

# Rank 3
rank_3_tensor = tf.constant([
    [[0, 1, 2, 3, 4],
     [5, 6, 7, 8, 9]],
    [[10, 11, 12, 13, 14],
     [15, 16, 17, 18, 19]],
    [[20, 21, 22, 23, 24],
     [25, 26, 27, 28, 29]]
])
print(rank_3_tensor)

# np.array / tensor.numpy ë©”ì†Œë“œë¡œ í…ì„œë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜ ê°€ëŠ¥.
np.array(rank_2_tensor)

rank_2_tensor.numpy()




# ------í…ì„œ ì—°ì‚°------
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]])

print(tf.add(a, b), '\n')
print(tf.multiply(a, b), '\n')
print(tf.matmul(a, b), '\n')
# -

print(a + b, '\n')
print(a * b, '\n')
print(a @ b, '\n')

# +
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# tf.reduce_max -> ê°€ì¥ í° ê°’ ì°¾ê¸°
print(tf.reduce_max(c))
# tf.argmax -> ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
print(tf.argmax(c))
# tf.nn.softmax -> softmax ì ìš©
print(tf.nn.softmax(c))




# ------í˜•ìƒ ì •ë³´------

rank_4_tensor = tf.zeros([3, 2, 4, 5])

print("Type of every element:", rank_4_tensor.dtype)
print("Number of dimensions:", rank_4_tensor.ndim)
print("Shape of tensor:", rank_4_tensor.shape)
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy())




# ------ì¸ë±ì‹±------

# ë‹¨ì¼ ì¶• ì¸ë±ì‹± : í‘œì¤€ íŒŒì´ì¬ ì¸ë±ì‹± ê·œì¹™ì„ ë”°ë¦„.
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())

print("First:", rank_1_tensor[0].numpy())
print("Second:", rank_1_tensor[1].numpy())
print("Last:", rank_1_tensor[-1].numpy())
# -

print("Everything:", rank_1_tensor[:].numpy())
print("Before 4:", rank_1_tensor[:4].numpy())
print("From 4 to the end:", rank_1_tensor[4:].numpy())
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
print("Every other item:", rank_1_tensor[::2].numpy())
print("Reversed:", rank_1_tensor[::-1].numpy())

# ë‹¤ì¶• ì¸ë±ì‹± : ì—¬ëŸ¬ ì¸ë±ìŠ¤ë¥¼ ì „ë‹¬í•˜ì—¬ ì¸ë±ì‹±.
print(rank_2_tensor.numpy())

print("[1, 1] ìœ„ì¹˜ì˜ ê°’: ", rank_2_tensor[1, 1].numpy())
print("Second row:", rank_2_tensor[1, :].numpy())
print("Second column:", rank_2_tensor[:, 1].numpy())
print("Last row:", rank_2_tensor[-1, :].numpy())
print("First item in last column:", rank_2_tensor[0, -1].numpy())
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")

# 3ì¶• í…ì„œ ì¸ë±ì‹±
print(rank_3_tensor[:, :, 4])




# ------í˜•ìƒ ì¡°ì‘í•˜ê¸°------

var_x = tf.Variable(tf.constant([[1], [2], [3]]))
print(var_x.shape)
# -

# íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
print(var_x.shape.as_list())

# reshapeë¡œ ìƒˆë¡œìš´ í˜•ìƒìœ¼ë¡œ ë³€í™˜. ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•  ëª¨ì–‘ì„ ëª…ì‹œ.
reshaped = tf.reshape(var_x, [1, 3])
print(var_x.shape)
print(reshaped.shape)

print(rank_3_tensor)

# shapeì„ '-1'ë¡œ ì§€ì •í•˜ë©´ ëª¨ì–‘ì— ë§ê²Œ ì•Œì•„ì„œ ë§ì¶°ì¤Œ.
print(tf.reshape(rank_3_tensor, [-1]))

# ì¼ë°˜ì ìœ¼ë¡œ tf.reshapeì˜ í•©ë¦¬ì ì¸ ìš©ë„ëŠ” ì¸ì ‘í•œ ì¶•ì„ ê²°í•©í•˜ê±°ë‚˜ ë¶„í• í•˜ëŠ” ê²ƒ.
# 3x2x5 í…ì„œì˜ ê²½ìš°, (3x2)x5 ë˜ëŠ” 3x(2x5)ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì 
print(tf.reshape(rank_3_tensor, [3*2, 5]), '\n')
print(tf.reshape(rank_3_tensor, [3, -1]))




# ------ë¸Œë¡œë“œìºìŠ¤íŒ…------

x = tf.constant([1, 2, 3])
y = tf.constant([2])
z = tf.constant([2, 2, 2])

print(tf.multiply(x, 2))
print(x * y)
print(x * z)

# +
x = tf.reshape(x, [3, 1])
y = tf.range(1, 5)

print(x, '\n')
print(y, '\n')
print(tf.multiply(x, y))

# +
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)




# ------ë¹„ì •í˜•(Ragged) í…ì„œ------

ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]
]
# -

# ë¹„ì •í˜• í…ì„œë¥¼ ì •ê·œ í…ì„œë¡œ í‘œí˜„ í•  ìˆ˜ ì—†ìŒ. -> tf.ragged.constant ì‚¬ìš©.
try:
    tensor = tf.constant(ragged_list)
except Exception as e:
    print(f"{type(e).__name__}: {e}")

ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)

print(ragged_tensor.shape)




# ------ë¬¸ìì—´ í…ì„œ------
# ë¬¸ìì—´ì€ Python ë¬¸ìì—´ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì¸ë±ì‹± ë¶ˆê°€. ë¬¸ìì—´ì˜ ê¸¸ì´ëŠ” í…ì„œì˜ ì°¨ì›ì´ ì•„ë‹˜.

# ìŠ¤ì¹¼ë¼ ë¬¸ìì—´ í…ì„œ
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)

# ë¬¸ìì—´ ë²¡í„°
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
print(tensor_of_strings)
# 'b'ì ‘ë‘ì‚¬ëŠ” dtypeì´ ìœ ë‹ˆì½”ë“œ ë¬¸ìì—´ì´ ì•„ë‹ˆë¼ ë°”ì´íŠ¸ ë¬¸ìì—´ì„ì„ ë‚˜íƒ€ëƒ„.

# ìœ ë‹ˆì½”ë“œ ë¬¸ìë¥¼ ì „ë‹¬í•˜ë©´ UTF-8ë¡œ ì¸ì½”ë”©ë¨.
tf.constant("ğŸ¥³ğŸ‘")

# tf.strings.split
print(tf.strings.split(scalar_string_tensor, sep=" "))
print(tf.strings.split(tensor_of_strings))

# tf.strings.to_number
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, sep=" ")))




# ------í¬ì†Œ í…ì„œ------

sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                      values=[1, 2],
                                      dense_shape=[3, 4])
print(sparse_tensor)
print(tf.sparse.to_dense(sparse_tensor))


